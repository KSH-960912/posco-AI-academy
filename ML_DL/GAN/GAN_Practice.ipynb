{"cells":[{"cell_type":"markdown","metadata":{"id":"NiP9H1n6u1N4"},"source":["## 모델 동작에 필요한 사전 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndYVmYg4u1N5"},"outputs":[],"source":["! pip install tensorflow_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIDmcz3Lu1N6"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","from tensorflow.keras import Model, layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmCCRSm5u1N6"},"outputs":[],"source":["os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)"]},{"cell_type":"markdown","metadata":{"id":"R9WJjBB5u1N6"},"source":["## 데이터 불러오기 및 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCssQhy5u1N6"},"outputs":[],"source":["# 이번 GAN 실습에 활용될 MNIST 데이터를 다운로드한 후,\n","# 불러온 데이터를 Training용과 Testing용으로 나누는 과정\n","# 모든 이미지 데이터의 크기는 28 x 28 x 1 (흑백)\n","\n","dataset = tfds.load('mnist', split = 'train')\n","batch_size = 1024\n","train_data = dataset.map(lambda data: tf.cast(data['image'], tf.float32) / 255.).batch(batch_size)"]},{"cell_type":"markdown","metadata":{"id":"CkhK8fQHu1N7"},"source":["## GAN 구현"]},{"cell_type":"markdown","metadata":{"id":"UjKc59Blu1N7"},"source":["### GAN의 생성자 (Generator) 구현"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rGB0yo3u1N7"},"outputs":[],"source":["# GAN의 생성자 (Generator)\n","\n","class Generator(Model):\n","    def __init__(self, latent_dim):\n","        super().__init__()\n","\n","        # 2D convolutional layer의 역연산에 해당하는 transposed 2D convolutional layer의 경우,\n","        # same padding을 적용하고 strides 값을 2로 할 경우 이미지의 크기가 두 배로 확장되는 효과!\n","        self.latent_dim = latent_dim\n","        self.generator = tf.keras.Sequential([\n","\n","            layers.Dense(7 * 7 * 32, activation = 'relu'),                                          # (batch_size, 7 * 7 * 32) , input_shape = (latent_dim, )\n","            layers.Reshape((7, 7, 32)),                                                             # (batch_size, 7, 7, 32)\n","            layers.Conv2DTranspose(64, 3, strides = 2, padding = 'same', activation = 'relu'),      # (batch_size, 14, 14, 64)\n","            layers.Conv2DTranspose(32, 3, strides = 2, padding = 'same', activation = 'relu'),      # (batch_size, 28, 28, 32)\n","            layers.Conv2DTranspose(1, 3, strides = 1, padding = 'same', activation = 'sigmoid')     # (batch_size, 28, 28, 1)\n","        ])\n","\n","    def call(self, z):\n","        return self.generator(z)"]},{"cell_type":"markdown","metadata":{"id":"tGys1bBDu1N7"},"source":["### GAN의 판별자 (Discriminator) 구현"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VN7pQ9syu1N7"},"outputs":[],"source":["# GAN의 판별자 (Discriminator)\n","\n","class Discriminator(Model):\n","    def __init__(self, latent_dim):\n","        super().__init__()\n","\n","        # 2D convolutional layer에서 same padding을 적용하고 strides 값을 2로 할 경우 이미지의 크기가 절반으로 줄어드는 효과!\n","        self.latent_dim = latent_dim\n","        self.discriminator = tf.keras.Sequential([\n","            layers.Conv2D(32, 3, strides = 2, activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),    # (batch_size, 14, 14, 32)\n","            layers.Conv2D(64, 3, strides = 2, activation = 'relu', padding = 'same'),                               # (batch_size, 7, 7, 64)\n","            layers.Flatten(),                                                                                       # (batch_size, 7 * 7 * 64)\n","            layers.Dense(1)                                                                                         # (batch_size, )\n","        ])\n","\n","    def call(self, x):\n","        return self.discriminator(x)"]},{"cell_type":"markdown","metadata":{"id":"-Re-ByBhu1N8"},"source":["### GAN 구조 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrJmxq8gu1N8"},"outputs":[],"source":["# Hyperparameters\n","\n","n_epochs = 200\n","latent_dim = 10\n","log_interval = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJVVSyI8u1N8"},"outputs":[],"source":["# GAN의 생성자와 판별자\n","\n","''' Fill here '''\n","\n","\n","\n","# Optimizer 정의\n","\n","''' Fill here '''"]},{"cell_type":"markdown","metadata":{"id":"cqDDhZgUu1N8"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"5sZpMoI0u1N8"},"source":["### Loss Function 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fws7jxFJu1N8"},"outputs":[],"source":["# Loss function은 binary cross entropy (BCE)로 정의\n","\n","''' Fill here '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22yHGxe9u1N8"},"outputs":[],"source":["def train_step(inputs):\n","    noises = tf.random.normal([batch_size, latent_dim])\n","\n","    with tf.GradientTape() as tape_g, tf.GradientTape() as tape_d:\n","        # noises: random noise 분포에서 sample된 벡터\n","        # x: noises로부터 생성된 MNIST 이미지\n","        # real_output: 실제 MNIST 이미지 판별 결과\n","        # fake_output: GAN의 생성자가 생성한 MNIST 이미지의 판별 결과\n","\n","        ''' Fill here '''\n","\n","        # Generator loss와 discriminator loss 계산\n","        ''' Fill here '''\n","\n","    # GAN을 구성하는 생성자와 판별자의 gradient 값들을 계산하는 과정\n","    grads_g = tape_g.gradient(loss_g, generator.trainable_variables)\n","    grads_d = tape_d.gradient(loss_d, discriminator.trainable_variables)\n","\n","    # 계산된 gradient 값들을 기반으로 GAN의 생성자와 판별자를 optimize하는 과정\n","    optimizer_g.apply_gradients(zip(grads_g, generator.trainable_variables))\n","    optimizer_d.apply_gradients(zip(grads_d, discriminator.trainable_variables))\n","\n","    return loss_g, loss_d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWUK4NNYu1N9"},"outputs":[],"source":["# 실제 Training 과정\n","\n","for epoch in range(1, n_epochs + 1):\n","    total_loss_g, total_loss_d = 0, 0\n","\n","    for x in train_data:\n","        ''' Fill here '''\n","\n","    if epoch % log_interval == 0:\n","        print(f'Epoch {epoch:3d} - Generator loss: {total_loss_g:.2f}, Discriminator loss: {total_loss_d:.2f}')"]},{"cell_type":"markdown","metadata":{"id":"KuJ95nmwu1N9"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"NOKJ6ypHu1N9"},"source":["### 생성자 동작 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJRp6N3hu1N9"},"outputs":[],"source":["# 학습된 GAN 모델의 생성자로 MNIST 이미지 Sampling 및 시각화\n","\n","noise = tf.random.normal([1, latent_dim])\n","x = generator(noise)\n","plt.imshow(x[0, :, :, 0], cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"gNEhLiivu1N9"},"source":["### 학습된 GAN 모델로 MNIST 이미지 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8TKJmC0u1N9"},"outputs":[],"source":["# 여러 개의 MNIST 이미지들을 Sampling하는 함수 정의\n","# n * n 정사각형 배치의 MNIST 이미지 생성 및 출력\n","\n","def plot_latent_images(n, digit_size = 28):\n","    image_width = digit_size * n\n","    image_height = image_width\n","    image = np.zeros((image_height, image_width))\n","\n","    for i in range(n):\n","        for j in range(n):\n","            noise = tf.random.normal([1, latent_dim])\n","            x = generator(noise)\n","            image[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size] = x[0, :, :, 0]\n","\n","    plt.figure(figsize = (10, 10))\n","    plt.imshow(image, cmap = 'Greys_r')\n","    plt.axis('Off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6j2-Q1Au1N9"},"outputs":[],"source":["# MNIST 이미지 생성\n","# 여기서는 10 * 10 = 100개의 MNIST 이미지 생성\n","\n","plot_latent_images(10)"]}],"metadata":{"kernelspec":{"display_name":"Youth_AI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}